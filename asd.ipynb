{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from fastai.vision.all import *\n",
    "import torchaudio\n",
    "import pathlib\n",
    "import librosa\n",
    "from IPython.display import Audio\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%config Completer.use_jedi = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = \"/home/john/Downloads/kaggle_respiratory_data/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/\"\n",
    "filenames = get_files(mypath, extensions='.wav')\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_diag = pd.read_csv(\"/home/john/Downloads/kaggle_respiratory_data/respiratory_sound_database/Respiratory_Sound_Database/patient_diagnosis.csv\",header=None) # patient diagnosis file\n",
    "p_diag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft=1024\n",
    "hop_length=256\n",
    "target_rate=44100\n",
    "num_samples=int(target_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method for labelling sample (Healthy/Unhealthy)\n",
    "def get_y(path): \n",
    "    desease = p_diag[p_diag[0] == int(path.stem[:3])][1].values[0]\n",
    "    if desease == \"Healthy\":\n",
    "        return \"Healthy\"\n",
    "    else : \n",
    "        return \"Unhealthy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Method for getting all audio files, I get file withc rate 44100 Hz only because resampling take so much time :( \n",
    "def get_items(path): \n",
    "    fns = [fn for fn in get_files(path, extensions='.wav') if torchaudio.load_wav(fn)[1] == target_rate]\n",
    "    return fns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Helper method to tranform audio array to Spectrogram\n",
    "au2spec = torchaudio.transforms.MelSpectrogram(sample_rate=target_rate,n_fft=n_fft, hop_length=hop_length, n_mels=256)\n",
    "ampli2db = torchaudio.transforms.AmplitudeToDB()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x(path, target_rate=target_rate, num_samples=num_samples*2):\n",
    "    x, rate = torchaudio.load_wav(path)\n",
    "    if rate != target_rate: \n",
    "        x = torchaudio.transforms.Resample(orig_freq=rate, new_freq=target_rate, resampling_method='sinc_interpolation')(x)\n",
    "    x = x[0] / 32768\n",
    "    x = x.numpy()\n",
    "    sample_total = x.shape[0]\n",
    "    randstart = random.randint(target_rate, sample_total-target_rate*3)\n",
    "    x = x[randstart:num_samples+randstart]\n",
    "    x = librosa.util.fix_length(x, num_samples)\n",
    "    torch_x = torch.tensor(x)\n",
    "    spec = au2spec(torch_x)\n",
    "    spec_db = ampli2db(spec)\n",
    "    spec_db = spec_db.data.squeeze(0).numpy()\n",
    "    spec_db = spec_db - spec_db.min()\n",
    "    spec_db = spec_db/spec_db.max()*255\n",
    "    return spec_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting all files and labels\n",
    "items = get_items(mypath)\n",
    "labels = [get_y(item) for item in items]\n",
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size=0.3\n",
    "splitter = TrainTestSplitter(test_size=test_size, random_state=42, stratify=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "db = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "    get_x=get_x,\n",
    "    get_y=get_y,\n",
    "    splitter=splitter,\n",
    "    item_tfms=[Resize(256)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dsets = db.datasets(items)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dsets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = Counter(labels)\n",
    "wgts = [1/count[dsets.vocab[label]] for img, label in dsets.train]\n",
    "wgts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = db.dataloaders(items, num_workers=2, dl_type=WeightedDL, wgts=wgts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## We use xresnet18 as model\n",
    "learn = cnn_learner(dls, xresnet18, metrics=error_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "learn.show_results()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix(figsize=(12,12), dpi=60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science_testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
